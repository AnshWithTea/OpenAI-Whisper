# OpenAI-Whisper
Project: AI-Powered Multilingual Audio Transcription with OpenAI Whisper

This project uses OpenAIâ€™s Whisper model to automatically transcribe audio files â€” including long recordings â€” into accurate text.
It is designed to run seamlessly on Google Colab, allowing you to mount audio files from Google Drive and process them without time limits.

    
Key Features

ğŸ™ Supports Any Length Audio â€” No 30-second restriction; transcribes entire MP3/WAV files in one go.

ğŸŒ Multilingual â€” Automatically detects and transcribes over 90 languages, including Hindi, English, and more.

ğŸ“„ Segmented Output â€” Provides text with timestamps for easy subtitle generation.

â˜ Colab-Friendly â€” Runs in Google Colab, mounts Google Drive for private file access, and works without exposing files publicly.

âš¡ Multiple Model Sizes â€” Choose between tiny, small, medium, or turbo for speed or accuracy. 

 		 
Tech Stack	

Python 3

Google Colab (for free GPU acceleration)

OpenAI Whisper library

Google Drive Integration


Use Cases

Transcribing podcasts, interviews, and lectures

Converting songs into text for analysis

Creating subtitles for videos

Speech-to-text for research or accessibility
