# OpenAI-Whisper
Project: AI-Powered Multilingual Audio Transcription with OpenAI Whisper

This project uses OpenAI’s Whisper model to automatically transcribe audio files — including long recordings — into accurate text.
It is designed to run seamlessly on Google Colab, allowing you to mount audio files from Google Drive and process them without time limits.

    
Key Features

🎙 Supports Any Length Audio — No 30-second restriction; transcribes entire MP3/WAV files in one go.

🌏 Multilingual — Automatically detects and transcribes over 90 languages, including Hindi, English, and more.

📄 Segmented Output — Provides text with timestamps for easy subtitle generation.

☁ Colab-Friendly — Runs in Google Colab, mounts Google Drive for private file access, and works without exposing files publicly.

⚡ Multiple Model Sizes — Choose between tiny, small, medium, or turbo for speed or accuracy. 

 		 
Tech Stack	

Python 3

Google Colab (for free GPU acceleration)

OpenAI Whisper library

Google Drive Integration


Use Cases

Transcribing podcasts, interviews, and lectures

Converting songs into text for analysis

Creating subtitles for videos

Speech-to-text for research or accessibility
